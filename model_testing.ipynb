{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from tweet_processor import generateTweetTensor\n",
    "from preprocess import genLabels\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import models\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torchtext import data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculateAcc(a, p):\n",
    "\n",
    "    b = len(a)\n",
    "    correct = 0\n",
    "    for i in range(0, b):\n",
    "        if a[i] < 0.5  and p[i] < 0.5:\n",
    "            correct += 1\n",
    "        elif a[i] > 0.5  and p[i] > 0.5:\n",
    "            correct += 1\n",
    "\n",
    "    acc = correct / b\n",
    "    return acc\n",
    "\n",
    "#Load Pre-trained model for Words\n",
    "print(\"Loading Pre-trained model of many tweets...\")\n",
    "glove = KeyedVectors.load_word2vec_format('glove.twitter.27B.100d.w2vformat.txt')\n",
    "print(\"Model loaded.\")\n",
    "\n",
    "# Load tweets from json\n",
    "\n",
    "model = models.RNN(100, 100)\n",
    "print(model.parameters())\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr= 0.01)\n",
    "optimizer.zero_grad()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_with_labels['onehot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Loading dataset...\")\n",
    "tweets = pd.read_json('trump_tweets_json.json')\n",
    "tweets = tweets[['created_at', 'text']]\n",
    "tweets_with_labels = genLabels(tweets)\n",
    "print(\"Loaded dataset.\")\n",
    "\n",
    "\n",
    "# Split sets into train, test, and validation\n",
    "print(\"Splitting data...\")\n",
    "rest_x, test_x, rest_y, test_y = train_test_split(tweets_with_labels, tweets_with_labels['onehot'], test_size=0.2, random_state=37)\n",
    "train_x, validate_x, train_y, validate_y = train_test_split(rest_x, rest_y, test_size=0.2, random_state=37)\n",
    "\n",
    "print(\"Generating vectors...\")\n",
    "# Generate vector of tweets\n",
    "loss_fnc = nn.BCEWithLogitsLoss()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Generating Test Vector...\")\n",
    "test_tweet_vector, test_lengths, test_nulls = generateTweetTensor(glove, test_x)\n",
    "test_y_tensor = torch.LongTensor([x for x in np.array(test_y)])\n",
    "test_y_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(0, len(test_nulls)):\n",
    "    i  = test_nulls[n] - n\n",
    "    test_y_tensor = torch.cat([test_y_tensor[0: i], test_y_tensor[i+1:]])\n",
    "\n",
    "test_dataset = torch.utils.data.TensorDataset(test_tweet_vector, test_y_tensor, torch.tensor(test_lengths))\n",
    "test_iter = DataLoader(test_dataset, batch_size=64, shuffle=True, num_workers=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Generating Validate Vector...\")\n",
    "validate_tweet_vector, validate_lengths, validate_nulls = generateTweetTensor(glove, validate_x)\n",
    "validate_y_tensor = torch.LongTensor([x for x in np.array(validate_y)])\n",
    "for n in range(0, len(validate_nulls)):\n",
    "    i  = validate_nulls[n] - n\n",
    "    validate_y_tensor = torch.cat([validate_y_tensor[0: i], validate_y_tensor[i+1:]])\n",
    "val_dataset = torch.utils.data.TensorDataset(validate_tweet_vector, validate_y_tensor, torch.tensor(validate_lengths))\n",
    "#val_iter = data.BucketIterator(val_dataset, batch_size=64, repeat=False, sort_key=lambda x: len(x.text))\n",
    "val_iter = DataLoader(val_dataset, batch_size=64, shuffle=True, num_workers=0)\n",
    "\n",
    "\n",
    "print(\"Generating Train Vector...\")\n",
    "train_tweet_vector, train_lengths, train_nulls = generateTweetTensor(glove, train_x)\n",
    "train_y_tensor = torch.LongTensor([x for x in np.array(train_y)])\n",
    "#actual = (torch.from_numpy(np.eye(10)[label])).float()\n",
    "\n",
    "\n",
    "for n in range(0, len(train_nulls)):\n",
    "    i  = train_nulls[n] - n\n",
    "    train_y_tensor = torch.cat([train_y_tensor[0: i], train_y_tensor[i+1:]])\n",
    "train_dataset = torch.utils.data.TensorDataset(train_tweet_vector, train_y_tensor, torch.tensor(train_lengths) )\n",
    "train_iter = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=0)\n",
    "\n",
    "\n",
    "print(\"Generated buckets.\")\n",
    "\n",
    "# Create rnn\n",
    "#model = models.RNN(100, 100)\n",
    "print(model.parameters())\n",
    "learning_rate = 0.01\n",
    "num_epochs = 25\n",
    "\n",
    "# Train models\n",
    "loss_fnc = nn.BCEWithLogitsLoss()\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "eps = []\n",
    "training_loss = []\n",
    "training_accs = []\n",
    "validation_loss = []\n",
    "validation_accs = []\n",
    "print(\"Model Created.\")\n",
    "\n",
    "for e in range(num_epochs):\n",
    "    eps += [e]\n",
    "    print(\"Epoch: \" + str(e))\n",
    "    for j, batch in enumerate(train_iter):\n",
    "        inputs = batch[0]\n",
    "        actual = batch[1]\n",
    "        lengths_float = batch[2]\n",
    "        lengths = lengths_float.long()\n",
    "        print(\"success\")\n",
    "        optimizer.zero_grad()\n",
    "        predicted = model(inputs,lengths)\n",
    "        loss = loss_fnc(predicted, actual.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(\"Calculating Training Accuracy...\")\n",
    "    # Calculate Training Accuracy\n",
    "    train_labels = []\n",
    "    train_preds = []\n",
    "\n",
    "\n",
    "    for k, t_batch in enumerate(train_iter):\n",
    "        t_inputs = t_batch[0]\n",
    "        t_actual = t_batch[1]\n",
    "        t_lengths_floats = t_batch[2]\n",
    "        t_lengths = t_lengths_floats.long()\n",
    "\n",
    "        train_labels += t_actual.tolist()\n",
    "        t_predicted = model(t_inputs, t_lengths)\n",
    "        train_preds += t_predicted.tolist()\n",
    "\n",
    "    t_acc = calculateAcc(train_labels, train_preds)\n",
    "    t_loss = loss_fnc(torch.FloatTensor(train_preds), torch.FloatTensor(train_labels))\n",
    "    training_accs += [t_acc]\n",
    "    training_loss += [t_loss.item()]\n",
    "    print(\"Training Accuracy: \" + str(t_acc))\n",
    "    print(\"Training Loss: \" + str(t_loss.item()))\n",
    "\n",
    "    # Calculate Validation Accuracy\n",
    "    valid_labels = []\n",
    "    valid_preds = []\n",
    "    for k, v_batch in enumerate(val_iter):\n",
    "        v_inputs = v_batch[0]\n",
    "        v_actual = v_batch[1]\n",
    "        v_lengths_floats = v_batch[2]\n",
    "        v_lengths = v_lengths_floats.long()\n",
    "        valid_labels += v_actual.tolist()\n",
    "        v_predicted = model(v_inputs, v_lengths)\n",
    "        valid_preds += v_predicted.tolist()\n",
    "\n",
    "    v_acc = calculateAcc(valid_labels, valid_preds)\n",
    "    v_loss = loss_fnc(torch.FloatTensor(valid_preds), torch.FloatTensor(valid_labels))\n",
    "    validation_accs += [v_acc]\n",
    "    validation_loss += [v_loss.item()]\n",
    "    print(\"Validation Accuracy: \" + str(v_acc))\n",
    "    print(\"Validation Loss: \" + str(v_loss.item()))\n",
    "\n",
    "# Calculate Testing Accuracy\n",
    "test_labels = []\n",
    "test_preds = []\n",
    "for k, t_batch in enumerate(test_iter):\n",
    "    t_inputs = t_batch[0]\n",
    "    t_actual = t_batch[1]\n",
    "    t_lengths_floats = t_batch[2]\n",
    "    t_lengths = t_lengths_floats.long()\n",
    "    test_labels += t_actual.tolist()\n",
    "    t_predicted = model(t_inputs, t_lengths)\n",
    "    test_preds += t_predicted.tolist()\n",
    "\n",
    "test_loss = loss_fnc(torch.FloatTensor(test_preds), torch.FloatTensor(test_labels))\n",
    "print(\"TESTING LOSS: \" + str(test_loss.item()))\n",
    "t_acc = calculateAcc(test_labels, test_preds)\n",
    "print(\"TESTING ACCURACY: \" + str(t_acc))\n",
    "\n",
    "#   Display Accuracy vs. Epoch\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(eps, training_accs, label='Training Data')\n",
    "ax.plot(eps, validation_accs, label='Validation Data')\n",
    "ax.set(xlabel='Number of Epochs', ylabel='Accuracy', title='Accuracy vs. Epoch')\n",
    "ax.set_ylim(0, 1)\n",
    "ax.grid()\n",
    "ax.legend()\n",
    "plt.show()\n",
    "\n",
    "#   Display Loss vs. Epoch\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(eps, training_loss, label='Training Data')\n",
    "ax.plot(eps, validation_loss, label='Validation Data')\n",
    "ax.set(xlabel='Number of Epochs', ylabel='Loss', title='Loss vs. Epoch')\n",
    "ax.set_ylim(0, 1)\n",
    "ax.grid()\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
